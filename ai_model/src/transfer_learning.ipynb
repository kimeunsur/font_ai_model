{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handwritten data shape: (200, 64, 64, 1)\n",
      "Number of labels: 200\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 함수\n",
    "def load_handwritten_images(image_dir, target_size=(64, 64)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    file_names = sorted(os.listdir(image_dir))\n",
    "    for file_name in file_names:\n",
    "        if file_name.endswith(\".jpg\"):\n",
    "            try:\n",
    "                img_path = os.path.join(image_dir, file_name)\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                if img is None:\n",
    "                    print(f\"Warning: Unable to read {img_path}\")\n",
    "                    continue\n",
    "                img = cv2.resize(img, target_size) / 255.0  # 픽셀 정규화\n",
    "                images.append(img)\n",
    "                label = os.path.splitext(file_name)[0]  # splittext 오타 수정\n",
    "                labels.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_name}: {e}\")\n",
    "    # NumPy 배열 변환 및 채널 차원 추가\n",
    "    images_array = np.expand_dims(np.array(images), axis=-1)\n",
    "    return images_array, labels\n",
    "\n",
    "# 손글씨 데이터 경로\n",
    "handwritten_path = \"/Users/kimeunsur/2024winter/4주차/font_images/seungmin_hw\"\n",
    "\n",
    "# 손글씨 데이터 로드\n",
    "X_handwritten, handwritten_labels = load_handwritten_images(handwritten_path)\n",
    "print(f\"Handwritten data shape: {X_handwritten.shape}\")\n",
    "print(f\"Number of labels: {len(handwritten_labels)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File format not supported: filepath=/Users/kimeunsur/2024winter/4주차/font_ai_model/ai_model/src/cnn.ipynb. Keras 3 only supports V3 `.keras` files and legacy H5 format files (`.h5` extension). Note that the legacy SavedModel format is not supported by `load_model()` in Keras 3. In order to reload a TensorFlow SavedModel as an inference-only layer in Keras 3, use `keras.layers.TFSMLayer(/Users/kimeunsur/2024winter/4주차/font_ai_model/ai_model/src/cnn.ipynb, call_endpoint='serving_default')` (note that your `call_endpoint` might have a different name).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 사전학습 모델 로드\u001b[39;00m\n\u001b[1;32m      5\u001b[0m pretrained_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/kimeunsur/2024winter/4주차/font_ai_model/ai_model/src/cnn.ipynb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m pretrained_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# 기존 모델의 Encoder-Decoder 구조 복사\u001b[39;00m\n\u001b[1;32m      9\u001b[0m encoder_input \u001b[38;5;241m=\u001b[39m pretrained_model\u001b[38;5;241m.\u001b[39minput[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/yes/envs/newenv/lib/python3.11/site-packages/keras/src/saving/saving_api.py:206\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    204\u001b[0m     )\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile format not supported: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeras 3 only supports V3 `.keras` files and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegacy H5 format files (`.h5` extension). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote that the legacy SavedModel format is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    211\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupported by `load_model()` in Keras 3. In \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    212\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morder to reload a TensorFlow SavedModel as an \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minference-only layer in Keras 3, use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`keras.layers.TFSMLayer(\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, call_endpoint=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserving_default\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(note that your `call_endpoint` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmight have a different name).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    218\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: File format not supported: filepath=/Users/kimeunsur/2024winter/4주차/font_ai_model/ai_model/src/cnn.ipynb. Keras 3 only supports V3 `.keras` files and legacy H5 format files (`.h5` extension). Note that the legacy SavedModel format is not supported by `load_model()` in Keras 3. In order to reload a TensorFlow SavedModel as an inference-only layer in Keras 3, use `keras.layers.TFSMLayer(/Users/kimeunsur/2024winter/4주차/font_ai_model/ai_model/src/cnn.ipynb, call_endpoint='serving_default')` (note that your `call_endpoint` might have a different name)."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 사전학습 모델 로드\n",
    "\n",
    "pretrained_model_path = \"/Users/kimeunsur/2024winter/4주차/font_ai_model/ai_model/src/cnn.ipynb\"\n",
    "pretrained_model = load_model(pretrained_model_path)\n",
    "\n",
    "# 기존 모델의 Encoder-Decoder 구조 복사\n",
    "encoder_input = pretrained_model.input[0]\n",
    "style_input = pretrained_model.input[1]\n",
    "encoded = pretrained_model.get_layer(\"max_pooling2d_1\").output  # 인코더 마지막 출력\n",
    "\n",
    "# 디코더 부분만 재구성 (Fine-Tuning용)\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "x = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "decoded = layers.Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "# Fine-Tuning 모델 생성\n",
    "fine_tuned_model = Model([encoder_input, style_input], decoded)\n",
    "fine_tuned_model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원-핫 인코딩된 스타일 정보 생성 (단일 손글씨 스타일로 가정)\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "style_label = 0  # 손글씨 스타일 번호\n",
    "style_labels = np.full((len(X_handwritten),), style_label)\n",
    "style_one_hot = to_categorical(style_labels, num_classes=1)  # 단일 클래스\n",
    "\n",
    "# 데이터 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val = train_test_split(X_handwritten, test_size=0.2, random_state=42)\n",
    "\n",
    "# 모델 학습\n",
    "history = fine_tuned_model.fit(\n",
    "    [X_train, style_one_hot[:len(X_train)]],  # 입력: 이미지와 스타일\n",
    "    X_train,                                 # 출력: 재구성된 이미지\n",
    "    validation_data=([X_val, style_one_hot[len(X_train):]], X_val),\n",
    "    epochs=50,\n",
    "    batch_size=16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 검증 데이터에서 예측 결과 생성\n",
    "reconstructed_images = fine_tuned_model.predict([X_val, style_one_hot[len(X_train):]])\n",
    "\n",
    "# 결과 시각화\n",
    "n = 5  # 시각화할 샘플 수\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i in range(n):\n",
    "    # 원본 이미지\n",
    "    plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(X_val[i].squeeze(), cmap='gray')\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # 복원된 이미지\n",
    "    plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(reconstructed_images[i].squeeze(), cmap='gray')\n",
    "    plt.title(\"Reconstructed\")\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
