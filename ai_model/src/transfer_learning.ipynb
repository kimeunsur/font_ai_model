{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드 함수\n",
    "def load_handwritten_images(image_dir, target_size=(64, 64)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    file_names = sorted(os.listdir(image_dir))\n",
    "    for file_name in file_names:\n",
    "        if file_name.endswith(\".png\"):\n",
    "            img = cv2.imread(os.path.join(image_dir, file_name), cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, target_size) / 255.0  # 픽셀 정규화\n",
    "            images.append(img)\n",
    "            labels.append(file_name.split(\".\")[0])  # 파일 이름에서 레이블 추출\n",
    "    return np.expand_dims(np.array(images), axis=-1), labels\n",
    "\n",
    "# 손글씨 데이터 경로\n",
    "handwritten_path = \"/Users/kimeunsur/2024winter/4주차/font_images/seungmin_hw\"\n",
    "\n",
    "# 손글씨 데이터 로드\n",
    "X_handwritten, handwritten_labels = load_handwritten_images(handwritten_path)\n",
    "print(f\"Handwritten data shape: {X_handwritten.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 사전학습 모델 로드\n",
    "pretrained_model_path = \"pretrained_cnn_model.h5\"\n",
    "pretrained_model = load_model(pretrained_model_path)\n",
    "\n",
    "# 기존 모델의 Encoder-Decoder 구조 복사\n",
    "encoder_input = pretrained_model.input[0]\n",
    "style_input = pretrained_model.input[1]\n",
    "encoded = pretrained_model.get_layer(\"max_pooling2d_1\").output  # 인코더 마지막 출력\n",
    "\n",
    "# 디코더 부분만 재구성 (Fine-Tuning용)\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "x = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "decoded = layers.Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "# Fine-Tuning 모델 생성\n",
    "fine_tuned_model = Model([encoder_input, style_input], decoded)\n",
    "fine_tuned_model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원-핫 인코딩된 스타일 정보 생성 (단일 손글씨 스타일로 가정)\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "style_label = 0  # 손글씨 스타일 번호\n",
    "style_labels = np.full((len(X_handwritten),), style_label)\n",
    "style_one_hot = to_categorical(style_labels, num_classes=1)  # 단일 클래스\n",
    "\n",
    "# 데이터 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val = train_test_split(X_handwritten, test_size=0.2, random_state=42)\n",
    "\n",
    "# 모델 학습\n",
    "history = fine_tuned_model.fit(\n",
    "    [X_train, style_one_hot[:len(X_train)]],  # 입력: 이미지와 스타일\n",
    "    X_train,                                 # 출력: 재구성된 이미지\n",
    "    validation_data=([X_val, style_one_hot[len(X_train):]], X_val),\n",
    "    epochs=50,\n",
    "    batch_size=16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 검증 데이터에서 예측 결과 생성\n",
    "reconstructed_images = fine_tuned_model.predict([X_val, style_one_hot[len(X_train):]])\n",
    "\n",
    "# 결과 시각화\n",
    "n = 5  # 시각화할 샘플 수\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i in range(n):\n",
    "    # 원본 이미지\n",
    "    plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(X_val[i].squeeze(), cmap='gray')\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # 복원된 이미지\n",
    "    plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(reconstructed_images[i].squeeze(), cmap='gray')\n",
    "    plt.title(\"Reconstructed\")\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
